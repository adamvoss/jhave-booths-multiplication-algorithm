\documentclass{article}

% The LaTeX-to-CNXML translator makes use of Tralics, a LaTeX-to-XML conversion
% utility.  Tralics has implemented all the packages in the LaTeX base directory,
% and it also supports a good number of supplemental LaTeX packages.  These
% supplemental packages are included in the \usepackage{} statements below.
% Packages not in the LaTeX base directory or \usepackage{} statements in this
% template are not supported by Tralics and, hence, not supported by the
% LaTeX-to-CNXML converter.

% If you have a question as to whether a specific LaTeX command is supported,
% please refer to the "HTML Documentation of all TeX commands" section at
% http://www-sop.inria.fr/apics/tralics/.  Here you will find links to manual pages
% organized alphabetically by the first letter of the command.  These pages indicate
% how Tralics handles conversion of each supported command, which informs how the
% LaTeX-to-CNXML translator behaves.

% To prepare your LaTeX document for import, copy the body of that document from its
% source and paste it into this template between the \begin{document} and \end{document}
% statements.  Do not attempt to use any packages other than the ones contained in this
% template.  You may, however, insert user-defined macros directly in this template
% before the \begin{document} statement.  Following this preparation, check to see if
% your template-compliant document can generate a .dvi (.pdf) using latex (pdflatex).
% If so, then your document is ready for import; if not, you must modify your document
% to generate an output file using only the packages supported by Tralics as described
% above.

%Is this in base?
%\usepackage{epsfig}
%\usepackage{epstopdf}
% Tralics supports the following AMS packages
% (see http://www-sop.inria.fr/apics/tralics/packages.html for details on full/partial
% support of package commands)
\usepackage{amsbsy,amscd,amsfonts,amsgen,amsmath,amsopn,amssymb,amstext,amsthm,amsxtra}

% Tralics supports \includegraphics and \scalebox, but not all other graphicx package
% commands; check the web documentation on supported commands before attempting to use
% other commands in the graphicx package:
\usepackage{graphicx}

% We must specifically invoke the verbatim package as follows to direct Tralics to handle
% the verbatim environment properly:
\usepackage{verbatim}

% Tralics also allows the following packages:
% (see http://www-sop.inria.fr/apics/tralics/packages.html for details on full/partial
% support of package commands)

%\usepackage{alltt}
%\usepackage{array}
%\usepackage{bracket}
%\usepackage{calc}
%\usepackage{delarray}
%\usepackage{eucal}
%\usepackage{eufrak}
%\usepackage{fancyverb}
%\usepackage{fix-cm}
%\usepackage{fixltx2e}
%\usepackage{flafter}
%\usepackage{fontenc}
%\usepackage{fp}
%\usepackage{graphpap}
%\usepackage{html}
%\usepackage{ifthen}
%\usepackage{index}
\usepackage[utf8]{inputenc}
%\usepackage{latexsym}
%\usepackage{lipsum}
%\usepackage{makeidx}
%\usepackage{minimal}
%\usepackage{mml}
%\usepackage{natbib}
%\usepackage{newlfont}
%\usepackage{oldlfont}
%\usepackage{shortvrb}
%\usepackage{showidx}
%\usepackage{soul}
%\usepackage{syntonly}
%\usepackage{textcase}
%\usepackage{textcomp}
%\usepackage{tloop}
%\usepackage{theorem}
%\usepackage{upref}

%-------------------------------------------------------------------
% You can insert user-defined macros (using the supported packages
% only) here...
\DeclareUnicodeCharacter{03B2}{\beta}
%-------------------------------------------------------------------

\begin{document}

\section{Objectives}
To understand how the process of multiplication can be translated into an efficient and relatively simple algorithm on the machine-register level for two's complement binary values using Booth's multiplication algorithm.

\section{Preparation}
Before using this module, it is best that the student be familiar with binary addition at the machine level and with two's complement representations of negative numbers, and have some knowledge of computer design.

\section{Introduction}
The process of multiplication is significantly more complex than that of addition.
The "simple" way to calculate a product would be through repeated additions.
Using this approach to calculate, for example, 11 x 23, you would start with 0 and add 11 to it 23 times.
This method is inefficient, especially using pencil and paper, and execution time varies wildly depending on the values multiplied, an undesirable property from a computer design point of view.
Several modifications must be made to this algorithm before we are ready to implement it in hardware.

\section{Shift-and-Add Multiplication}
First, recall the standard method taught to students to multiply two numbers, sometimes called the "shift and add" method.
This involves multiplying one number, hereafter called the multiplicand (or the value in register M, which we will come back to shortly), by successively more significant digits of the other number, hereafter referred to as the multiplier (or the value in register Q).
The results of these individual multiplications are referred to as "partial products".

We notate this as the sum of all $M \cdot q_i$, where $q_i$ is bit $i$ from Q and $i$ ranges from 0 to one less than the number of digits in Q.
For binary values, there are only two cases to consider: $M \cdot 0 = 0$, or $M \cdot 1 = M$.

Consider the following calculation of the multiplication of 001011 and 010111, which in two's complement notation are 11 and 23, respectively.
To stay consistent with register conventions, we use the same number of bits to represent both values.
%diagram goes here

%\begin{figure}
%\centering
\includegraphics[scale=0.5]{saam2.pdf}
%\end{figure}

We see already a vast improvement in the performance of this algorithm, compared to the repeated additions method.
Each of the partial products shown corresponds to an addition operation (+M or +0).
In every line except the first, there is also an implicit shift operation.
There are 5 additions and 4 shifts for a total of 9 operations, compared to the proposed 23 earlier in the textbook.
The speedup is even greater if one considers that, on some machines, shift operations can potentially take less time than addition operations.

\section{Problems with the Shift-and-Add Method}
There are several issues that prevent us from directly implementing the shift-and-add algorithm into hardware.
To begin with, most ALUs are only capable of adding two numbers together at a time.
This means a running total must be calculated with every partial product, instead of at the very end of the process.
We will call the space used to store the running product register A.

Also note that as the algorithm progresses, the position at which the numbers are added incrementally slides to the left.
It is a much simpler task to design a machine that always adds into the same location and then shifts the running product to the right.
This will be referred to as an \emph{arithmetic shift right}, or \emph{asr} for short.
It is an arithmetic shift, instead of a logic shift, because we wish to preserve the sign of the running product as we do our calculations.

Finally, we need to consider register size.
In the previous example, the numbers we multiplied were represented as 6-digit binary values; their result, however, required 10 bits to represent.
In general, if two n-bit numbers are multiplied, then the representation of the result can require as many as 2n bits to represent.
Thus the convention is to store the result of multiplication in two registers.

\section{Improved Shift-and-Add Multiplication}
Here is an improved of the shift-and-add multiplication algorithm, with the proposed changes: %diagram goes here

\includegraphics[scale=0.5]{isaam3.pdf}

There is another detail to consider before implementing this algorithm in hardware: in the last example, the bit in the multiplier Q we are using to calculate a partial product is always positioned one to the left of the previous bit we used, or it is the rightmost (least significant) bit of Q.
To make this process easier, we could instead choose to always examine the least significant bit of Q, and for every right shift operation on register A, we would also do a right shift on Q.
Thus, when the algorithm finishes, all of the previous values in Q will be discarded.
This fact will allow us to be even more efficient: instead of using another register to store the lower half of the product, we can use Q, because for every bit discarded from Q, we can place into Q's most significant bit the least significant bit of A, saving ourselves from using a whole other register!

%TODO diagram with registers from visualization

\section{The Problem with Negative Numbers}
Consider the multiplication of the following 4-bit 2's complement numbers using the algorithm we have been discussing: 0011 (3) and 1011 (-5).
We should expect a result of -15 (11110001); however, our current method is unable to distinguish between signed and unsigned values, and would multiply 3 by 11 (the unsigned decimal value of 1011).
One way around this behavior would be to calculate the absolute values for any given M and Q.
Then, after the positive product was calculated, if either M or Q but not both are negative, calculate the two's complement of the product.

\section{Booth's Encoding}
In 1951, Andrew Booth introduced an alternative method for multiplying two's complement numbers.
At its heart is the observation that a number like 0111, which is understood to mean $2^2 + 2^1 + 2^0 = 4 + 2 + 1 = 7$, can also be thought of as $2^3 - 2^0 = 8 - 1 = 7$.
This can be written ("encoded") as $100\bar{1}$, where 1 and 0 have their understood meanings, and $\bar{1}$ represents a subtraction of the power of 2 of its position, in this case $-(2^0)$ or -1.

    In general, it can be shown that any number of the form $2^n + 2^{n-1} + ...
+ 2^{n-k}$ is equal to $2^{n+1} - 2^{n-k}$.
For binary values, this translates into the following: for every string of 1s in the binary value, replace the rightmost (least significant) 1 with -, replace the first 0 on the left of the string (if it exists) with 1, and set all the 1s between these two to 0.
For the case where the "string" of ones is a single bit, ie $...010...$,
the appropriate encoding would be $...1\bar{1}0...$,
which is correct because $2^n = 2^{n+1} - 2^n$.
%TODO better math

This method works for negative two's complement values as well.
There are two cases to consider: either the most significant bit is followed by 0 (such as 1001, or -7) or else it terminates a longer string of 1s (such as 1101 or 1111, which are -3 and -1 respectively).
In the first case, the most significant bit is converted to $\bar{1}$, representing a subtraction of the value in M.
Since this bit represents a lager value than the sum of the powers of two all the other bits represent, the final value will be negative.
In the second case, all of the 1s in the leftmost string will turn into 0s except for the right most bit, which will be converted into $\bar{1}$.
Again, this guarantees that the most significant non-zero bit in the binary value is negative, so that the whole number itself will be negative.
Let $k$ be the most significant $\bar{1}$ in an encoded negative number.
The value of that encoded number can then be expressed as $-2^k + \sum_{i=0}^k q_i^{\prime} \cdot 2^i$ (where $q_i^{\prime}$ is the value of bit i in the encoded binary number).
Recall that the original negative two's complement number has the value $-2^k + \sum_{i=0}^k q_i \cdot 2^i$.
Since from our given description $k$ is the same in both equations, and we have shown the sums to be equivalent, we verify that the two represent the same value.


\section{Booth's Algorithm in Hardware}
    At the hardware level we are only allowed the use of 0 and 1 for values, so we must examine pairs of bits in order to determine our case.
Scanning a binary number from right to left, a pair '10' signifies the beginning of a string of 1s and thus corresponds to a subtraction.
A '01' pair signifies the end of a string of 1s and corresponds to an addition.
The pairs '00' and '11' signify that no arithmetic operations need occur.
Since we would like to stay as close as possible to the algorithm outlined earlier, all cases will still require a shift.

    In order to examine pairs of bits, we add an extra 1 bit register, called $\beta$ (or Beta) to hold the bit shifted out of Q.
$\beta$ is initialized to 0, so that at the start of the algorithm, if the least significant bit of Q is 1, it will correspond to a subtraction.
Keep in mind now that whenever a shift occurs, the least significant bit of A is moved into the most significant bit of Q, and the least significant bit of Q is moved into $\beta$.
The old value of $\beta$ is discarded.

\section{Visualization of Booth's Multiplication}
Everything we have considered so far for an appropriate machine level algorithm to multiply two's complement values has been implemented as a JHAVE visualization.
Instead of using the form of the previous examples, it more closely resembles the way the algorithm might be executed in hardware, placing explicitly the multiplicand and multiplier in registers M and Q respectively, and storing the final result in registers A and Q.
An example run-through is provided below.
Step through the visualization as many times as you need, answering the questions as they appear, then proceed on to the exercises.

%-------------------------------------------------------------------
% to create references, un-comment \bibliographystyle{plain} and
% un-comment \bibliography{myBIBfile} and re-name its arguemnt(s)
% to point at the .bib file(s) containing the BibTeX references:

%\bibliographystyle{plain}
%\bibliography{myBIBfile}

\end{document}
